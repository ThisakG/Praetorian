# Praetorian â€” Anomaly Detection & Analytics Dashboard

Praetorian is a machine-learningâ€“powered anomaly detection system built using <b>Isolation Forest<b>, featuring an interactive Streamlit web interface, real-time scoring, visualization, model evaluatiob, and CSV exporting capabilities. 

This learning project / demo was creating in order to get a glimpse of how security teams can analyse user session data, derive anomaly scores, detect risky behaviour and visualize insights. 

Dashboard: http://192.168.1.15:8502 


# ğŸš€ Features

### ğŸ” 1. **Preprocessing Python Scripts**
- Cleans raw authentication logs  ()
- Extracts temporal features  
- One-hot encodes categorical fields  
- Converts IPv4 addresses into numeric vectors  
- Scales numerical features using MinMaxScaler  
- Ensures test data matches the modelâ€™s training schema  

### ğŸ§  2. **Machine Learning Model**
- Uses an Isolation Forest for anomaly detection  
- Supports:
  - Decision function scoring  
  - Prediction output (`Normal` / `Anomaly`)  
  - Threshold-based risk scoring  

### ğŸ“Š 3. **Interactive Streamlit Dashboard**
- Upload raw CSV files or preprocessed CSV files  
- Automatic preprocessing detection  
- Visual anomaly tables  
- Score distribution plots  
- Highlighting of suspicious events  
- Exportable results  

---

# ğŸ“ Project Structure
```
Praetorian/
| 
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ dashboard.py # Streamlit UI
â”‚ â”œâ”€â”€ preprocess.py # Preprocessing functions (train + test)
â”‚ â””â”€â”€ utils.py # (Optional) Helper functions
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ train.csv
â”‚ â”œâ”€â”€ test.csv
â”‚ â”œâ”€â”€ train_preprocessed.csv
â”‚ â”œâ”€â”€ test_preprocessed.csv
â”‚ â””â”€â”€ scaler.save # Saved MinMaxScaler
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ anomaly_model.pkl # Trained Isolation Forest
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ training.ipynb # Model development experiments
â”‚
â”œâ”€â”€ plots/
â”‚ â””â”€â”€ charts.png # Saved visualizations (optional)
â”‚
â””â”€â”€ README.md
```

# ğŸ¢ System Architecture Visualized
```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚           Synthetic Data              â”‚
 â”‚     (data/generate_synthetic.py)      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚          Preprocessing Layer          â”‚
 â”‚          (src/preprocess.py)          â”‚
 â”‚   - timestamp â†’ hour                  â”‚
 â”‚   - one-hot encode device_type        â”‚
 â”‚   - IP address â†’ 4 numerical features â”‚
 â”‚   - scaling (MinMaxScaler)            â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚          Model Training               â”‚
 â”‚         (models/train_model.py)       â”‚
 â”‚      - Isolation Forest               â”‚
 â”‚      - Model saved as .joblib         â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚       Streamlit Dashboard (app/)      â”‚
 â”‚    Upload CSV â†’ Preprocess/Score â†’    â”‚
 â”‚        Visualize anomalies            â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
---

# ğŸ”§ Tech stack

- Python 3.10
- Python libraries: pandas, numpy, scikit-learn (Isolation forest), matplotlib, seaborn, joblib, streamlit
- HTML (UI)

---

# Why Isolation Forest

Robust for high-dimensional log data

Unsupervised â†’ no need for exact labels

Outputs anomaly score + prediction

Lightweight & production-ready

# ğŸ§¬ Synthetic Dataset Generation

Synthetic data simulates user login events across devices, locations, and times.

Fields Included:

- timestamp

- muser_id

- device_type

- ip

-login_success

- session_duration

- failed_attempts

- location

- label (normal/anomalous)

# How anomalies were simulated

- Random IPs with rare subnets

- High failed login attempts

- Odd login hours

- Suspicious session durations

- Unusual device/location combos

- Generated using:

- data/generate_synthetic.py


# Seperated the sythetic data by a train-test split

train.csv (80%)
test.csv  (20%)

# ğŸ§¼ Preprocessing Logic (src/preprocess.py)

Preprocessing is identical for training and test data, with consistent handling of categorical and numerical fields.

âœ” Convert timestamp â†’ hour: This captures temporal behaviour while removing timezone noise.

âœ” One-hot encode device_type: Example:device_Windows, device_Linux, device_MacOS, device_Android, device_iOS

âœ” Test-time logic auto-creates missing device columns so the model never breaks.

âœ” Convert IP ("A.B.C.D") â†’ ip_1 â€¦ ip_4: Treats each octet as an independent feature.

âœ” Scale numerical columns: Using MinMaxScaler saved as scaler.save

âœ” Numerical fields: login_success, failed_attempts, session_duration, hour, ip_1, ip_2, ip_3, ip_4

âœ” Output

Two files:

train_preprocessed.csv
test_preprocessed.csv

# ğŸ¤– Model Training (models/train_model.py)

The script:

âœ” Loads preprocessed train data

âœ” Fits Isolation Forest

âœ” Saves trained model â†’ models/isolation_forest.joblib

âœ” Optionally evaluates using accuracy and confusion matrix

# Model outputs:

âœ” decision_function(X) â†’ anomaly score
âœ” predict(X) â†’ [-1 = anomaly, 1 = normal]

# ğŸ“Š Streamlit Dashboard (app/dashboard.py)

The heart of the project.

Features:

âœ” Auto upload CSV (preprocessed)

âœ” Auto-detect whether preprocessing is needed

âœ” Score dataset using Isolation Forest

âœ” Display: Top anomalies, Score distribution, Device breakdown, Failed login patterns, Suspicious hours

âœ” Download results as CSV



# â–¶ï¸ How to Run the Project

1ï¸âƒ£ Clone the repository
git clone https://github.com/<yourusername>/Praetorian.git
cd Praetorian

2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate   # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Train the model (optional)
python models/train_model.py

5ï¸âƒ£ Run the Streamlit dashboard
streamlit run app/dashboard.py


# ğŸ§ª How the Whole Project Works Together

1. Synthetic data created â†’ stored in /data/

2. Preprocessing performed â†’ saves scaler + preprocessed datasets

3. Model trained â†’ saved as .joblib

4. Dashboard loads model + scaler

â†’ accepts new data
â†’ preprocesses if needed
â†’ generates anomaly score + prediction
â†’ displays results interactively
